{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd6f2b5-d1ef-48b7-b3c2-1b91db4df68d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (0.10.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from scikit-optimize) (1.4.2)\n",
      "Requirement already satisfied: pyaml>=16.9 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from scikit-optimize) (24.7.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from scikit-optimize) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from scikit-optimize) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from scikit-optimize) (1.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from scikit-optimize) (24.1)\n",
      "Requirement already satisfied: PyYAML in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
      "Requirement already satisfied: dask-expr in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (1.1.14)\n",
      "Requirement already satisfied: dask==2024.9.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask-expr) (2024.9.0)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask-expr) (17.0.0)\n",
      "Requirement already satisfied: pandas>=2 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask-expr) (2.2.3)\n",
      "Requirement already satisfied: click>=8.1 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask==2024.9.0->dask-expr) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask==2024.9.0->dask-expr) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask==2024.9.0->dask-expr) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask==2024.9.0->dask-expr) (24.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask==2024.9.0->dask-expr) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask==2024.9.0->dask-expr) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from dask==2024.9.0->dask-expr) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from pandas>=2->dask-expr) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from pandas>=2->dask-expr) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from pandas>=2->dask-expr) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from pandas>=2->dask-expr) (2024.2)\n",
      "Requirement already satisfied: locket in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from partd>=1.4.0->dask==2024.9.0->dask-expr) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/elpibedeflorida/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2->dask-expr) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize\n",
    "!pip install dask-expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65184af-7bb5-40e9-8846-98fc4b7c0150",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BayesSearchCV' from 'sklearn.model_selection' (/home/elpibedeflorida/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrdinalEncoder, OneHotEncoder\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, BayesSearchCV\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier , GradientBoostingClassifier , HistGradientBoostingClassifier\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BayesSearchCV' from 'sklearn.model_selection' (/home/elpibedeflorida/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, BayesSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier , HistGradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, log_loss, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99766050-f4d2-4f4c-a02e-b7d934fdc9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.6f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153037d-f59d-4ffb-88b6-97f64f3fb1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = r\"~/buckets/b1/datasets/Detalle_Ratio_1079_20240801151755.txt\" #Davox P1\n",
    "path_2 = r\"~/buckets/b1/datasets/Detalle_Ratio_1080_20240802120040.txt\" #Davox P2\n",
    "path_3 = r\"~/buckets/b1/datasets/Detalle_Ratio_1081_20240802135513.txt\" #FS FIJA P1\n",
    "path_4 = r\"~/buckets/b1/datasets/Detalle_Ratio_1082_20240805111624.txt\" #FS FIJA P2\n",
    "path_5 = r\"~/buckets/b1/datasets/Detalle_Ratio_1083_20240805101000.txt\" #FS MOVIL P1\n",
    "path_6 = r\"~/buckets/b1/datasets/Detalle_Ratio_1084_20240805125725.txt\" #SCL P1\n",
    "path_7 = r\"~/buckets/b1/datasets/Detalle_Ratio_1086_20240805153333.txt\" #SCL P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5bccd-2bca-4a75-ae50-00bbf2e1e269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(path_1 , sep = \"|\" )\n",
    "df_2 = pd.read_csv(path_2 , sep = \"|\" )\n",
    "df_3 = pd.read_csv(path_3 , sep = \"|\" )\n",
    "df_4 = pd.read_csv(path_4 , sep = \"|\" )\n",
    "df_5 = pd.read_csv(path_5 , sep = \"|\" )\n",
    "df_6 = pd.read_csv(path_6 , sep = \"|\" )\n",
    "df_7 = pd.read_csv(path_7 , sep = \"|\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ba829-dd71-435f-8508-404b00d7a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c455ff-6749-45b8-b2e0-bc97904c1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63dd25a-1518-428d-94df-dd06fd7da103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bc425-8703-457b-a662-470c3dc3bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf7917-0184-46c3-bb39-291416d35659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e79ae-a0b1-4aa4-b5a7-d3e55d0e2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035789c-c898-4b39-a24b-e4ef5ea5988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68bd05-b326-4c05-8b4d-39201024523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.concat([df_1 , df_2 , df_3 , df_4 , df_5 , df_6 , df_7])\n",
    "#df  = pd.concat([df_5 , df_6 , df_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f85566b-9d6e-483e-aa2c-809d71fa2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(\"PERIODO_FACTURADO\")[\"CLIENTE\"].size().reset_index(name='count')\n",
    "df_sorted = df_grouped.sort_values(by=\"PERIODO_FACTURADO\", ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8017264-7a42-4f71-9957-52fe0f7b2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b132435-79f8-4403-9397-8a3a361fdf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_1\n",
    "del df_2\n",
    "del df_3\n",
    "del df_4\n",
    "del df_5\n",
    "del df_6\n",
    "del df_7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b22de8-35ad-4183-8903-0fd2e3c43cda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6ba51-a504-42f6-bf89-233b423ccc72",
   "metadata": {},
   "source": [
    "## Wrangling\n",
    "\n",
    "Aca voy a empezar a preparar los datos, iniciando con las variables tipo fecha, dado que para el FE necesito tener una base que me permita enriquecer el modelo final\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30dee36-7676-4d41-8bb7-72a58ea157d3",
   "metadata": {},
   "source": [
    "### Features tipo datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ba4f4-9870-4aab-9038-52a56638b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino las columnas que estan en la posicion de 50 en adelante, son inutiles y no aportan valor, no pertenecen a lo que el segmento maneja sino a datos de orientados a B2C\n",
    "df.drop(columns=df.columns[50:], inplace = True)\n",
    "\n",
    "#Formateo algunas columnas relacionadas a fechas como formato manejable \n",
    "df['PERIODO_FACTURADO'] = df['PERIODO_FACTURADO'].astype(str)\n",
    "df['PERIODO_VENCIMIENTO'] = df['PERIODO_VENCIMIENTO'].astype(str)\n",
    "df[\"CICLO\"] = df[\"CICLO\"].astype(str).str.replace(\".0\" , \"\",regex=True)\n",
    "\n",
    "# Convertir PERIODO_FACTURADO a principio de mes\n",
    "df['PERIODO_FACTURADO'] = pd.to_datetime(df['PERIODO_FACTURADO'] + '01', format='%Y%m%d') \n",
    "\n",
    "# Convertir PERIODO_VENCIMIENTO a fin de mes\n",
    "df['PERIODO_VENCIMIENTO'] = pd.to_datetime(df['PERIODO_VENCIMIENTO'] + '01', format='%Y%m%d') + pd.offsets.MonthEnd(0)\n",
    "\n",
    "#df[\"CICLO\"] = pd.to_datetime(df[\"CICLO\"] , format=\"%Y%m%d\",coerce = True)\n",
    "\n",
    "df[\"PERIODO_CONTRATO\"] = (df['PERIODO_VENCIMIENTO']-df['PERIODO_FACTURADO']).dt.days\n",
    "\n",
    "\n",
    "#Formateo la columna cliente para que sea legible\n",
    "df[\"CLIENTE\"] = df[\"CLIENTE\"].astype(str).str.split('-').str[0]\n",
    "\n",
    "df['PERIODO_FACTURADO'] = df['PERIODO_FACTURADO'].dt.date\n",
    "df['PERIODO_VENCIMIENTO'] = df['PERIODO_VENCIMIENTO'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffb206-cc36-4d8e-8d9f-7eb2e69ca3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino las variables que no aportan dado que fueron creadas principalmente para el segmento B2C\n",
    "drop_cols = [\"CICLO\",\"CARTERA_CANALES\",\"CARRIERS\",\"INTRAGRUPO\",\"SEGMENTO\",\"SEGMENTO_AGRUPADO\",\"RIESGO_ORIGINACION\",\"RIESGO_CARTERA\",\"FEC_ALTA\",\"TIPO_DOCUMENTO\",\"SEGMENTO_HOMOLOGADO\"]\n",
    "df.drop(columns=drop_cols , inplace = True)\n",
    "\n",
    "# Ordeno por periodo\n",
    "df = df.sort_values(by='PERIODO_FACTURADO', ascending=True)\n",
    "periodos = df[\"PERIODO_FACTURADO\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b832f-3d5a-4046-ae2e-cd076beae86b",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "En esta seccion se va a transformar los features que buscan mejorar el rendimiento del un modelo.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a466ea-a593-44b6-be44-8aff1faf659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de columna de desplazamiento para ver el valor anterior(1 y 2 meses) de S0.\n",
    "\n",
    "df['S0_PREV'] = df.groupby([\"CLIENTE\"])['S0'].shift(1)\n",
    "df['S0_PREV2'] = df.groupby([\"CLIENTE\"])['S0'].shift(2)\n",
    "df['S0_PREV3'] = df.groupby([\"CLIENTE\"])['S0'].shift(3)\n",
    "\n",
    "# Diferencial entre pagos previos, si crece o disminuyen\n",
    "df['GAP_PM2M'] = df['S0_PREV'] - df['S0_PREV2']\n",
    "df['GAP_PM2M2'] = df['S0_PREV2'] - df['S0_PREV3']\n",
    "df['GAP_PM2M'] = df['GAP_PM2M'].fillna(0)\n",
    "df['GAP_PM2M2'] = df['GAP_PM2M2'].fillna(0)\n",
    "\n",
    "# Generacion de  media movil de 3 meses para la facturacion / pagos a S0\n",
    "\n",
    "#df[\"S0_3EMA\"] = df.groupby([\"CLIENTE\"])['FACTURA_REAL'].rolling(window=3).mean()\n",
    "#df[\"S0_3EMA\"] = df.groupby([\"CLIENTE\"])['S0'].rolling(window=3).mean()\n",
    "\n",
    "df[\"FACT_3EMA\"] = df.groupby(\"CLIENTE\")['FACTURA_REAL'].transform(lambda x: x.rolling(window=3).mean())\n",
    "df[\"S0_3EMA\"] = df.groupby(\"CLIENTE\")['S0'].transform(lambda x: x.rolling(window=3).mean())\n",
    "\n",
    "# Determinacion si un cliente pago el mes anterior en S0\n",
    "df['PAGO_UM'] = df.apply(lambda row: 1 if row['S0_PREV'] > 0  else 0, axis=1)\n",
    "\n",
    "# Determinar si un cliente pagó el mes anterior y no pagó este mes\n",
    "df['PAGO_UM_C'] = df.apply(lambda row: 1 if row['S0_PREV'] > 0 and row['S0'] == 0 else 0, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Dropeo la columna\n",
    "#df = df.drop(columns=\"S0_PREV\") lo comente el 22-08-2024 a modo de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f466a59-b85e-4864-96e5-d7e0f78bc813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c9b2c-983d-4e95-83bc-1c76d33580f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generacion de la variable objetivo, es decir, a predecir\n",
    "\n",
    "# Creacion de columna de desplazamiento para ver el valor futuro de S0\n",
    "df['S0_NEXT'] = df.groupby('CLIENTE')['S0'].shift(-2)\n",
    "\n",
    "# Determinacion de si un cliente pagará el próximo mes en la semana 0\n",
    "df['PAGO_PM_C'] = df['S0_NEXT'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Drop de la columna temporal S0_NEXT\n",
    "df = df.drop(columns=['S0_NEXT']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8cf475-0768-4984-8169-a206527eeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupo los pagos cada 4 semanas, a excepcion de pago a vencimiento (S0).\n",
    "\n",
    "df[\"0S\"] = (df[\"S0\"]  ) \n",
    "df[\"4S\"] = ( df[\"S1\"] +df[\"S2\"] +df[\"S3\"] + df[\"S4\"]  ) \n",
    "df[\"8S\"] = (df[\"S5\"] + df[\"S6\"] +df[\"S7\"] +df[\"S8\"] ) \n",
    "df[\"12S\"] = (df[\"S9\"] + df[\"S10\"] +df[\"S11\"] +df[\"S12\"] ) \n",
    "df[\"16S\"] = (df[\"S13\"] + df[\"S14\"] +df[\"S15\"] +df[\"S16\"] ) \n",
    "df[\"20S\"] = (df[\"S17\"] + df[\"S18\"] +df[\"S19\"] +df[\"S20\"] ) \n",
    "df[\"24S\"] = (df[\"S21\"] + df[\"S22\"] +df[\"S23\"] +df[\"S24\"] ) \n",
    "\n",
    "# Genero una variable que sea proporcional al pago\n",
    "\n",
    "PR_S0 = pd.DataFrame((df.groupby(\"CLIENTE\")[\"S0\"].sum() / df.groupby(\"CLIENTE\")[\"FACTURA_REAL\"].sum()), columns=[\"PR_S0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe42583-5317-40db-8878-cb7f5a921405",
   "metadata": {},
   "source": [
    "## Train-Test\n",
    "\n",
    "Preparo el dataframe para train-test-validation, utilizo encodes sobre variables categoricas y limpio variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ccc8f-2360-49ed-917c-e33f696776ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saco las features que ya estan incluidas en las agrupaciones\n",
    "\n",
    "drop_cols_S = ['S0', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10',\n",
    "       'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20',\n",
    "       'S21', 'S22', 'S23', 'S24']\n",
    "df.drop(columns=drop_cols_S,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e5bff-98dc-427c-962e-970b08289dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteo a  Cliente como indice para facilitar el merge.\n",
    "\n",
    "df = df.reset_index().set_index(\"CLIENTE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc696fb-12f0-49b6-b589-24eec3b919b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupo segun antiguedad de clietne.\n",
    "\n",
    "df[\"VIGENCIA\"] = np.where (df[\"VIGENCIA\"] == \"Alta Antigua Mayor a 12 meses\" , \"Mayor a 12 meses\" , df[\"VIGENCIA\"])\n",
    "df[\"VIGENCIA\"] = np.where ( (df[\"VIGENCIA\"] == \"Alta Nueva hasta 3 meses\") | (df[\"VIGENCIA\"] == \"Alta Nueva de 4 a 6 meses\")  , \"Menor o igual a 6 meses\" , df[\"VIGENCIA\"])\n",
    "df[\"VIGENCIA\"] = np.where ( (df[\"VIGENCIA\"] == \"Entre 6 y 12 meses\")  , \"Alta Nueva de 7 a 12 meses\" , df[\"VIGENCIA\"])\n",
    "\n",
    "# soluciono inconsistencias en los segmentos de atencion\n",
    "\n",
    "df[\"SEGMENTO_ATENCION\"] = np.where (df[\"SEGMENTO_ATENCION\"] == \"EMPRESAS \",\"EMPRESAS\",df[\"SEGMENTO_ATENCION\"]  )\n",
    "df[\"SEGMENTO_ATENCION\"] = np.where (df[\"SEGMENTO_ATENCION\"] == \"Empresas\",\"EMPRESAS\",df[\"SEGMENTO_ATENCION\"]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc35672-c1d1-4134-a156-8005c8d51190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames utilizando el índice.\n",
    "\n",
    "df_combined = pd.merge(df, PR_S0, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c2d61b-7148-436e-949f-37c9c45398be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero una nueva base.\n",
    "\n",
    "df_combined = df_combined.reset_index()\n",
    "df_combined = df_combined.sort_values(\"PERIODO_VENCIMIENTO\")\n",
    "\n",
    "# Saco las columnas que no van a aportar para el train test validation\n",
    "drop_comb = [\"PREFIJO\" , \"index\" ,\"NUMERO_FACTURA\"  , \"PERIODO_VENCIMIENTO\" , \"DEPARTAMENTO\", \"NUM_IDENT\",\"CLIENTE\",\"OFERTA\" ]\n",
    "df_combined.drop(columns=drop_comb, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f110ac54-0fd3-4f7a-a14b-da062df0406c",
   "metadata": {},
   "source": [
    "### Encodes ( Ordinal y One-hot )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c2b2e-206d-40ff-8242-9c42f1426aad",
   "metadata": {},
   "source": [
    "#### Ordinal \n",
    "\n",
    "Lo uso sobre la variable  vigencia, que me dice la antiguedad del cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8ddad-7781-4dfb-bba6-e0fe01742a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplico ordinal encoder para el atributo \"VIGENCIA\" que representa la permanencia dentro de TEF de c/empresa\n",
    "\n",
    "# Lista de categorías ordenadas de menor a mayor\n",
    "\n",
    "orden_categorias = [\"Menor o igual a 6 meses\", \"Alta Nueva de 7 a 12 meses\", \"Mayor a 12 meses\"]\n",
    "\n",
    "#Aplico conversion\n",
    "\n",
    "ord_enc = OrdinalEncoder(categories=[orden_categorias])\n",
    "\n",
    "# Aplicar el encoder a la columna\n",
    "\n",
    "df_combined['VIGENCIA'] = ord_enc.fit_transform(df_combined[['VIGENCIA']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c56699-1bc3-4a6f-96a3-d0cacde507ed",
   "metadata": {},
   "source": [
    "### One Hot\n",
    "\n",
    "Utilizo One Hot para la variable Segmento con los distintos ambitos de atencion ( Corporaciones, Empresas y Pyme ) y sobre la base de facturacion (Davox, SCL , FS movil y fija )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784cb583-34cc-4a8d-80ae-97cd72c76ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Segmento\n",
    "\n",
    "# Initialize the encoder\n",
    "oh_enc_seg = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n",
    "# Perform the one-hot encoding\n",
    "encoded_columns_segmento = oh_enc_seg.fit_transform(df_combined[['SEGMENTO_ATENCION']])\n",
    "\n",
    "# Create a DataFrame with the encoded columns\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_columns_segmento, columns=oh_enc_seg.get_feature_names_out(['SEGMENTO_ATENCION']))\n",
    "\n",
    "# Concatenate the original DataFrame (excluding the original column) with the encoded DataFrame\n",
    "\n",
    "df_combined = pd.concat([df_combined.drop(columns=['SEGMENTO_ATENCION']), encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa696a6-7bfc-4afa-9fc4-ee54da217bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Base\n",
    "\n",
    "oh_enc_base = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_columns_base = oh_enc_base.fit_transform(df_combined[[\"BASE\"]])\n",
    "encoded_df = pd.DataFrame(encoded_columns_base , columns = oh_enc_base.get_feature_names_out([\"BASE\"]))\n",
    "df_combined = pd.concat( [df_combined.drop(columns=[\"BASE\"]) , encoded_df] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b03b8c-ef3c-4036-ba7d-d4b035ff8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.shape[0]*0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c6dc2-6293-4213-8fe0-7afb0d3c1ed0",
   "metadata": {},
   "source": [
    "### Train-Test\n",
    "\n",
    "Separo para realizar train test split, una consideracion es que no voy a realizar una corrida de final train ( por el momento )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0749e34-2698-4038-87d7-c455a15a6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saco las etiquetas del ultimo periodo, no cumplen ninguna funcion.\n",
    "\n",
    "ultimo_periodo_sin_etiqueta = df_combined [df_combined[\"PERIODO_FACTURADO\"] == pd.Timestamp(\"2024-07-01\").date()]\n",
    "\n",
    "df_combined.drop(df_combined[df_combined[\"PERIODO_FACTURADO\"] == pd.Timestamp(\"2024-07-01\").date()].index, inplace=True)\n",
    "\n",
    "df_combined.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a480e-8587-4170-930c-5be8875834d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "test = df_combined[df_combined[\"PERIODO_FACTURADO\"] >= pd.Timestamp(\"2024-03-01\").date()]\n",
    "train = df_combined[df_combined[\"PERIODO_FACTURADO\"] < pd.Timestamp(\"2024-03-01\").date()]\n",
    "\n",
    "test.drop(columns = \"PERIODO_FACTURADO\",inplace=True)\n",
    "train.drop(columns = \"PERIODO_FACTURADO\",inplace=True)\n",
    "\n",
    "X_train = train.drop(columns=[\"PAGO_PM_C\"])\n",
    "y_train = train[\"PAGO_PM_C\"]\n",
    "X_test = test.drop(columns=[\"PAGO_PM_C\"])\n",
    "y_test = test[\"PAGO_PM_C\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36026e0b-796b-4e3d-acc2-19834361c272",
   "metadata": {},
   "source": [
    "## Modelo~parametrizacion\n",
    "\n",
    "El modelo a utilizar va a ser light gradient boosting dado que en corrida preliminar demostro \n",
    "rendimiento superior, optimizacion de parametros mediante optimizacion bayesiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f45d81-8a07-4701-b89d-e1f36e4f25a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definir el modelo\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "\n",
    "# Calcular el número total de muestras\n",
    "total_samples = len(train)\n",
    "\n",
    "# Definir el espacio de búsqueda basado en porcentajes\n",
    "param_space = {\n",
    "    'num_leaves': Integer(32, 512),\n",
    "    'max_depth': Integer(3, 8),\n",
    "    'learning_rate': Real(0.05, 0.1, prior='log-uniform'),\n",
    "    'n_estimators': Integer(400, 700),\n",
    "    'min_data_in_leaf': Integer(int(0.01 * total_samples), int(0.05 * total_samples)),  # 1% a 5% del total de muestras\n",
    "}\n",
    "\n",
    "# Configurar la búsqueda bayesiana con múltiples métricas\n",
    "opt = BayesSearchCV(\n",
    "    lgbm,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=100,  \n",
    "    cv=5,\n",
    "    scoring={\n",
    "        'accuracy': 'accuracy',\n",
    "        'roc_auc': 'roc_auc',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'f1': 'f1'\n",
    "    },  # Diccionario de métricas\n",
    "    refit='accuracy',  # Refit para optimizar por 'accuracy' (puedes cambiarlo)\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917353cc-12d9-4877-967e-ca839dc99480",
   "metadata": {},
   "outputs": [],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1b501-337d-4bfd-9e5a-1f23916e4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar todos los resultados de la búsqueda\n",
    "results = pd.DataFrame(opt.cv_results_)\n",
    "results.to_csv('lgbm_bayesian_optimization_results_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be8779-088c-464e-83a4-d2ee2b641165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo\n",
    "best_model = opt.best_estimator_\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Crear un DataFrame para visualizar mejor\n",
    "features = X_train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Mostrar la importancia de las características\n",
    "print(importance_df)\n",
    "\n",
    "# Graficar la importancia de las características\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Importancia de las Características')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9961e5ea-121d-4d86-8d1c-046c04f70774",
   "metadata": {},
   "source": [
    "### Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea89e58-60bc-4e90-82bc-05f990e833a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperar los 10 mejores modelos\n",
    "top_10_models = opt.cv_results_['params'][:10]\n",
    "\n",
    "# Inicializar un DataFrame para almacenar las métricas de cada modelo\n",
    "metrics_df = pd.DataFrame(columns=['Model', 'Accuracy', 'ROC AUC', 'Log Loss', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Evaluar cada uno de los 10 mejores modelos en el conjunto de validación\n",
    "for i, params in enumerate(top_10_models):\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en el conjunto de validación\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred_proba = model.predict_proba(X_valid)[:, 1]  # Para ROC AUC y Log Loss\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    roc_auc = roc_auc_score(y_valid, y_pred_proba)\n",
    "    log_loss_val = log_loss(y_valid, y_pred_proba)\n",
    "    precision = precision_score(y_valid, y_pred)\n",
    "    recall = recall_score(y_valid, y_pred)\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    \n",
    "    # Almacenar las métricas en el DataFrame\n",
    "    metrics_df = metrics_df.append({\n",
    "        'Model': f'Model {i+1}',\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC AUC': roc_auc,\n",
    "        'Log Loss': log_loss_val,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Ordenar los modelos por ROC AUC para identificar el mejor\n",
    "metrics_df = metrics_df.sort_values(by='ROC AUC', ascending=False)\n",
    "\n",
    "print(metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
